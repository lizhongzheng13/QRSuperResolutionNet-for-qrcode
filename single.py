import torch
# import argparse # <--- ç§»é™¤ argparse
from PIL import Image
import numpy as np
from torchvision import transforms
from pyzbar.pyzbar import decode
import os
import time

# å‡è®¾ä½ çš„æ¨¡åž‹å®šä¹‰åœ¨ 'model.py' æ–‡ä»¶ä¸­
# ç¡®ä¿ model.py ä¸Žæ­¤è„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹æˆ–åœ¨ Python è·¯å¾„ä¸­
try:
    from model import QRSuperResolutionNet
except ImportError:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥æ¨¡åž‹å®šä¹‰ã€‚è¯·ç¡®ä¿ 'model.py' æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å« QRSuperResolutionNet ç±»ã€‚")
    exit()


def preprocess_image(image_path, device):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
    try:
        img = Image.open(image_path).convert('L')
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šè¾“å…¥å›¾ç‰‡æœªåœ¨ {image_path} æ‰¾åˆ°")
        return None
    except Exception as e:
        print(f"æ‰“å¼€å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        return None
    transform = transforms.Compose([
        transforms.ToTensor()
    ])
    img_tensor = transform(img).unsqueeze(0).to(device)
    return img_tensor


def postprocess_image(tensor):
    """å°†æ¨¡åž‹è¾“å‡ºçš„ Tensor è½¬æ¢å›ž PIL å›¾åƒ"""
    img_np = tensor.squeeze(0).squeeze(0).detach().cpu().numpy()
    img_np = np.clip(img_np * 255, 0, 255).astype(np.uint8)
    pil_img = Image.fromarray(img_np, mode='L')
    return pil_img

# main å‡½æ•°ä¿æŒä¸å˜ï¼Œå®ƒæœŸæœ›æŽ¥æ”¶ä¸€ä¸ªåŒ…å«é…ç½®å±žæ€§çš„å¯¹è±¡ (ä¹‹å‰æ˜¯ args)


def main(config):  # <--- å‡½æ•°ç­¾åä¸å˜ï¼ŒæŽ¥æ”¶ä¸€ä¸ªé…ç½®å¯¹è±¡
    # --- 0. è®¾ç½®è®¾å¤‡ ---
    if config.use_cpu:  # <--- ä½¿ç”¨ config.use_cpu
        device = torch.device("cpu")
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨çš„è®¾å¤‡: {device}")

    # --- 1. åŠ è½½æ¨¡åž‹ ---
    if not os.path.exists(config.weights):  # <--- ä½¿ç”¨ config.weights
        print(f"é”™è¯¯ï¼šæ¨¡åž‹æƒé‡æ–‡ä»¶æœªåœ¨ {config.weights} æ‰¾åˆ°")
        return

    model = QRSuperResolutionNet(
        in_channels=1,
        out_channels=1,
        base_channels=config.base_channels,  # <--- ä½¿ç”¨ config.base_channels
        num_blocks=config.num_blocks      # <--- ä½¿ç”¨ config.num_blocks
    )
    try:
        model.load_state_dict(torch.load(
            config.weights, map_location=device, weights_only=True))
        model.to(device)
        model.eval()
        print("æ¨¡åž‹åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"åŠ è½½æ¨¡åž‹æƒé‡æ—¶å‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦ä¸Žæ¨¡åž‹ç»“æž„åŒ¹é…ï¼ˆé€šé“æ•°ã€å—æ•°ç­‰ï¼‰ã€‚")
        return

    # --- 2. é¢„å¤„ç†è¾“å…¥å›¾åƒ ---
    print(f"æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†è¾“å…¥å›¾åƒ: {config.input}")  # <--- ä½¿ç”¨ config.input
    lr_tensor = preprocess_image(config.input, device)
    if lr_tensor is None:
        return
    print(f"è¾“å…¥å›¾åƒå¼ é‡å°ºå¯¸: {lr_tensor.shape}")

    # --- 3. æ‰§è¡Œè¶…åˆ†è¾¨çŽ‡ ---
    print("å¼€å§‹æ‰§è¡Œè¶…åˆ†è¾¨çŽ‡å¤„ç†...")
    start_time = time.time()
    with torch.no_grad():
        sr_tensor = model(lr_tensor)
    end_time = time.time()
    print(f"è¶…åˆ†è¾¨çŽ‡å¤„ç†å®Œæˆã€‚è€—æ—¶: {end_time - start_time:.4f} ç§’")
    print(f"è¾“å‡ºå›¾åƒå¼ é‡å°ºå¯¸: {sr_tensor.shape}")

    # --- 4. åŽå¤„ç†è¾“å‡ºå›¾åƒ ---
    sr_image_pil = postprocess_image(sr_tensor)

    # --- 5. å°è¯•è§£ç äºŒç»´ç  ---
    print("æ­£åœ¨å°è¯•è§£ç è¶…åˆ†è¾¨çŽ‡å¤„ç†åŽçš„äºŒç»´ç ...")
    try:
        decoded_objects = decode(sr_image_pil)
    except Exception as e:
        print(f"ä½¿ç”¨ pyzbar è§£ç æ—¶å‡ºé”™: {e}")
        decoded_objects = []

    if decoded_objects:
        print("-" * 30)
        print("ðŸŽ‰ æˆåŠŸè§£ç äºŒç»´ç ï¼")
        for i, obj in enumerate(decoded_objects):
            try:
                data = obj.data.decode('utf-8')
            except UnicodeDecodeError:
                data = obj.data
            print(f"  ç»“æžœ {i+1}:")
            print(f"    ç±»åž‹: {obj.type}")
            print(f"    æ•°æ®: {data}")
        print("-" * 30)
    else:
        print("-" * 30)
        print("âŒ æœªèƒ½ä»Žè¶…åˆ†è¾¨çŽ‡å›¾åƒä¸­è§£ç äºŒç»´ç ã€‚")
        print("-" * 30)

    # --- 6. (å¯é€‰) ä¿å­˜è¾“å‡ºå›¾åƒ ---
    if config.output:  # <--- ä½¿ç”¨ config.output
        try:
            output_dir = os.path.dirname(config.output)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            sr_image_pil.save(config.output)
            print(f"è¶…åˆ†è¾¨çŽ‡å›¾åƒå·²ä¿å­˜åˆ°: {config.output}")
        except Exception as e:
            print(f"ä¿å­˜è¾“å‡ºå›¾åƒæ—¶å‡ºé”™: {e}")

    # --- 7. (å¯é€‰) ä¿å­˜åŽŸå§‹å°ºå¯¸å¯¹æ¯”å›¾ ---
    if config.compare:  # <--- ä½¿ç”¨ config.compare
        try:
            lr_img = Image.open(config.input).convert('L')
            bicubic_img = lr_img.resize(sr_image_pil.size, Image.BICUBIC)
            total_width = bicubic_img.width + sr_image_pil.width
            max_height = max(bicubic_img.height, sr_image_pil.height)
            comparison_img = Image.new('L', (total_width, max_height))
            comparison_img.paste(bicubic_img, (0, 0))
            comparison_img.paste(sr_image_pil, (bicubic_img.width, 0))
            compare_path = os.path.splitext(config.output)[
                0] + "_compare.png" if config.output else "comparison.png"
            comparison_img.save(compare_path)
            print(f"å¯¹æ¯”å›¾åƒ (å·¦: Bicubic, å³: SR) å·²ä¿å­˜åˆ°: {compare_path}")
        except Exception as e:
            print(f"åˆ›å»ºæˆ–ä¿å­˜å¯¹æ¯”å›¾åƒæ—¶å‡ºé”™: {e}")


# å®šä¹‰ä¸€ä¸ªç®€å•çš„ç±»æ¥å­˜å‚¨é…ç½®ï¼Œæ¨¡æ‹Ÿ argparse çš„ Namespace å¯¹è±¡
class Config:
    pass


if __name__ == "__main__":
    # --- ç›´æŽ¥åœ¨æ­¤å¤„è®¾ç½®å‚æ•° ---
    config = Config()  # åˆ›å»ºä¸€ä¸ªç©ºå¯¹è±¡æ¥å­˜å‚¨é…ç½®

    # **å¿…é¡»** ä¿®æ”¹ä¸‹é¢çš„è·¯å¾„ä¸ºä½ è‡ªå·±çš„æ–‡ä»¶è·¯å¾„
    # <--- *** EDIT THIS PATH ***
    # config.input = "/root/autodl-tmp/for_me/dataset/test/lr/qr_286.png"
    config.input = "/root/autodl-tmp/for_me/dataset_3_yasuo/test/lr/qr_768.png"
    # <--- *** EDIT THIS PATH ***
    config.weights = "/root/autodl-tmp/for_me/mine_model_v1/checkpoints/qr_sr_epoch30.pth"

    # **å¯é€‰** ä¿®æ”¹ä¸‹é¢çš„å‚æ•°
    config.output = "output_sr.png"             # è¾“å‡ºæ–‡ä»¶å
    config.compare = True                       # æ˜¯å¦ä¿å­˜å¯¹æ¯”å›¾ (True æˆ– False)
    config.base_channels = 64                   # æ¨¡åž‹çš„ base_channels (å¿…é¡»ä¸Žæƒé‡åŒ¹é…)
    config.num_blocks = 5                       # æ¨¡åž‹çš„ num_blocks (å¿…é¡»ä¸Žæƒé‡åŒ¹é…)
    config.use_cpu = False                      # æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ CPU (True æˆ– False)
    # --- å‚æ•°è®¾ç½®ç»“æŸ ---

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (å¯é€‰ä½†æŽ¨è)
    if not os.path.exists(config.input):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ°: {config.input}")
    elif not os.path.exists(config.weights):
        print(f"é”™è¯¯ï¼šæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {config.weights}")
    else:
        # ä½¿ç”¨è®¾ç½®å¥½çš„ config å¯¹è±¡è°ƒç”¨ main å‡½æ•°
        main(config)
